{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rake-nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-fvgTFX4nQ3",
        "outputId": "27579df0-e971-479b-e97d-cc91cbcf31b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake-nltk) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.1)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('all')\n",
        "!pip install keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yikwTKDN5U8v",
        "outputId": "971a6b31-633c-4ec8-8387-cfe29a71dcdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import re\n",
        "import string, sys, os\n",
        "from rake_nltk import Rake\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import io\n",
        "from io import StringIO\n",
        "import sys\n",
        "import random\n",
        "from transformers import pipeline\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "choices = []\n",
        "\n",
        "def find_key(sent, tagged_list):\n",
        "    flag = 0\n",
        "    for tag in tagged_list:\n",
        "        if(tag[1] == 'NNP'):\n",
        "            key_word = tag[0]\n",
        "            flag = 1\n",
        "            break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NNPS'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NN'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NNS'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "\n",
        "    if(flag == 1):\n",
        "        display(sent, key_word)\n",
        "\n",
        "def display(qtn, ans):\n",
        "    blank = '________'\n",
        "    qtn = re.sub(ans, blank, qtn, 1, flags=re.IGNORECASE)\n",
        "    mc = []\n",
        "    disp_mc = []\n",
        "    mc = random.sample(choices, 3)\n",
        "    mc.append(ans)\n",
        "    disp_mc = random.sample(mc, 4)\n",
        "\n",
        "    print(\"Q:\", qtn)\n",
        "    i = 1\n",
        "    for choice in disp_mc:\n",
        "        print(i, \".\", choice)\n",
        "        i = i + 1\n",
        "    print(\"\\nAns:\", ans, \"\\n\")\n",
        "\n",
        "    questions.append(qtn)\n",
        "    answers.append(ans)\n",
        "    outF = open('questions.txt', \"a\")\n",
        "    outF.write(\"Q:\")\n",
        "    outF.write(qtn)\n",
        "    outF.write(\"\\n\")\n",
        "    outF.write(\"Options:\")\n",
        "    outF.write(str(disp_mc))\n",
        "    outF.write(\"\\nAns:\")\n",
        "    outF.write(ans)\n",
        "    outF.write(\"\\n\\n\")\n",
        "    outF.close()\n",
        "\n",
        "# Read summary into text and tokenize text into sentences in collection\n",
        "filename = sys.argv[1]\n",
        "with open(\"/content/input.txt\") as f:\n",
        "    text = f.read()\n",
        "f.close()\n",
        "collection = sent_tokenize(text)\n",
        "\n",
        "# Find noun keywords from text using TextBlob\n",
        "blob = TextBlob(text)\n",
        "keywords = blob.noun_phrases\n",
        "\n",
        "for keyword in keywords:\n",
        "    choices.append(keyword)\n",
        "\n",
        "# Create a T5 question answering pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"t5-base\", tokenizer=\"t5-base\")\n",
        "\n",
        "# Find the relevant keywords from each sentence\n",
        "r = Rake(min_length=1, max_length=1)\n",
        "for collec in collection:\n",
        "    r.extract_keywords_from_text(collec)\n",
        "    if(r.get_ranked_phrases()):\n",
        "        phrase_list = r.get_ranked_phrases()\n",
        "        tagged = nltk.pos_tag(phrase_list)\n",
        "        find_key(collec, tagged)\n",
        "        # Use T5 to answer a question about the sentence\n",
        "        result = qa_pipeline({\n",
        "            \"context\": collec,\n",
        "            \"question\": \"What is the main idea of this sentence?\"\n",
        "        })\n",
        "        main_idea = result[\"answer\"]\n",
        "        print(\"Main Idea:\", main_idea)"
      ],
      "metadata": {
        "id": "_5PDqB1pIjrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6848187-9075-469c-d81c-b70c6a34da6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Harry Potter is a ________ of seven fantasy novels written by British author J. K. Rowling.\n",
            "1 . new information\n",
            "2 . harry potter\n",
            "3 . series\n",
            "4 . harry potter\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Main Idea: Harry Potter is a\n",
            "Q: The novels chronicle the lives of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and ________.\n",
            "1 . commercial success worldwide\n",
            "2 . j. k. rowling\n",
            "3 . wizardry\n",
            "4 . studio tour\n",
            "\n",
            "Ans: wizardry \n",
            "\n",
            "Main Idea: novels chronicle the lives of a\n",
            "Q: The main story arc concerns Harry's conflict with Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic, and subjugate all wizards and Muggles (________-magical people).\n",
            "1 . harry potter\n",
            "2 . dark wizard\n",
            "3 . total value\n",
            "4 . non\n",
            "\n",
            "Ans: non \n",
            "\n",
            "Main Idea: The main story arc concerns Harry's conflict with Lord Voldemort,\n",
            "Q: The ________ was originally published in English by Bloomsbury in the United Kingdom and Scholastic Press in the United States.\n",
            "1 . series\n",
            "2 . stone\n",
            "3 . numerous derivative\n",
            "4 . british school story\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Main Idea: series was originally published in English by Bloomsbury\n",
            "Q: A series of many genres, including fantasy, drama, coming-of-age fiction, and the British school story (which includes elements of mystery, thriller, adventure, horror, and romance), the ________ of Harry Potter explores numerous themes and includes many cultural meanings and references.\n",
            "1 . novels chronicle\n",
            "2 . world\n",
            "3 . ministry\n",
            "4 . commercial success worldwide\n",
            "\n",
            "Ans: world \n",
            "\n",
            "Main Idea: many genres, including fantasy, drama, coming-of-age\n",
            "Q: [1] Major themes in the series include prejudice, corruption, ________, and death.\n",
            "1 . harry potter\n",
            "2 . harry potter\n",
            "3 . madness\n",
            "4 . immense popularity\n",
            "\n",
            "Ans: madness \n",
            "\n",
            "Main Idea: Major themes in the series include prejudice, corruption, madness,\n",
            "Q: [2][3]\n",
            "\n",
            "Since the release of the first novel, Harry Potter and the Philosopher's ________, on 26 June 1997, the books have found immense popularity, positive reviews, and commercial success worldwide.\n",
            "1 . amusement parks\n",
            "2 . bloomsbury\n",
            "3 . eight-part namesake film series\n",
            "4 . stone\n",
            "\n",
            "Ans: stone \n",
            "\n",
            "Main Idea: Since the release of the first novel, Harry Potter and the Philosopher's\n",
            "Main Idea: They have attracted a\n",
            "Q: [4][5] As of February 2023, the books have sold more than 600 million copies worldwide, making them the best-selling book series in ________, and have been available in 85 languages.\n",
            "1 . story co-written\n",
            "2 . non-magical people\n",
            "3 . hermione granger\n",
            "4 . history\n",
            "\n",
            "Ans: history \n",
            "\n",
            "Main Idea: making them the best-selling\n",
            "Q: [6] The last four books consecutively set records as the fastest-selling books in history, with the final instalment selling roughly 2.7 million copies in the United Kingdom and 8.3 million copies in the United States within twenty-four hours of its ________.\n",
            "1 . release\n",
            "2 . numerous themes\n",
            "3 . ] major themes\n",
            "4 . bloomsbury\n",
            "\n",
            "Ans: release \n",
            "\n",
            "Main Idea: books consecutively set records as the fastest-selling\n",
            "Q: The original seven books were adapted into an eight-part namesake film series by Warner Bros. ________.\n",
            "1 . pictures\n",
            "2 . commercial success worldwide\n",
            "3 . non-magical people\n",
            "4 . digital platform\n",
            "\n",
            "Ans: pictures \n",
            "\n",
            "Main Idea: books were adapted into an eight-part namesake\n",
            "Q: In 2016, the total value of the Harry Potter franchise was estimated at $25 billion,[7] making Harry Potter one of the highest-grossing media franchises of all ________.\n",
            "1 . find them\n",
            "2 . ] making\n",
            "3 . time\n",
            "4 . harry potter\n",
            "\n",
            "Ans: time \n",
            "\n",
            "Main Idea: making Harry Potter one of the highest-grossing\n",
            "Main Idea: Harry Potter and the Cursed Child is a\n",
            "Q: The success of the books and films has allowed the Harry Potter franchise to expand with numerous derivative works, a travelling exhibition that premiered in Chicago in 2009, a studio tour in London that opened in 2012, a digital platform on which J. K. Rowling updates the series with new information and insight, and a ________ of spin-off films premiering in November 2016 with Fantastic Beasts and Where to Find Them, among many other developments.\n",
            "1 . kingdom\n",
            "2 . harry potter\n",
            "3 . trilogy\n",
            "4 . ] making\n",
            "\n",
            "Ans: trilogy \n",
            "\n",
            "Main Idea: has allowed the Harry Potter franchise to expand with numerous derivative works, a\n",
            "Q: Themed attractions, collectively known as The Wizarding ________ of Harry Potter, have been built at several Universal Destinations & Experiences amusement parks around the world.\n",
            "1 . world\n",
            "2 . harry potter\n",
            "3 . kingdom\n",
            "4 . harry potter\n",
            "\n",
            "Ans: world \n",
            "\n",
            "Main Idea: Themed attractions, collectively known as The Wizarding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(text_without_period,text)\n",
        "print(f\"ROUGE Scores: {scores}\")"
      ],
      "metadata": {
        "id": "PuGfW9PPPPDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d304c0d0-64f3-4458-f945-b739d71f00f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge1': Score(precision=0.8893805309734514, recall=1.0, fmeasure=0.9414519906323184), 'rouge2': Score(precision=0.8603104212860311, recall=0.9675810473815462, fmeasure=0.9107981220657276), 'rougeL': Score(precision=0.8893805309734514, recall=1.0, fmeasure=0.9414519906323184)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import re\n",
        "import string,sys,os\n",
        "from rake_nltk import Rake\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import io\n",
        "from io import StringIO\n",
        "import sys\n",
        "import random\n",
        "\n",
        "questions=[]\n",
        "answers=[]\n",
        "choices=[]\n",
        "\n",
        "def find_key(sent,tagged_list):\n",
        "    flag=0\n",
        "    for tag in tagged_list:\n",
        "        if(tag[1]=='NNP'):\n",
        "            key_word=tag[0]\n",
        "            flag=1\n",
        "            break\n",
        "    if(flag==0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1]=='NNPS'):\n",
        "                key_word=tag[0]\n",
        "                flag=1\n",
        "                break\n",
        "    if(flag==0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1]=='NN'):\n",
        "                key_word=tag[0]\n",
        "                flag=1\n",
        "                break\n",
        "    if(flag==0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1]=='NNS'):\n",
        "                key_word=tag[0]\n",
        "                flag=1\n",
        "                break\n",
        "    #tagged_list_copy=tagged_list\n",
        "    if(flag==1):\n",
        "        display(sent,key_word)\n",
        "\n",
        "def display(qtn,ans):\n",
        "    blank='________'\n",
        "    qtn = re.sub(ans, blank, qtn, 1, flags=re.IGNORECASE)\n",
        "    #qtn=str.replace(qtn,ans,blank)\n",
        "    mc=[]\n",
        "    disp_mc=[]\n",
        "    mc=random.sample(choices, 3)\n",
        "    mc.append(ans)\n",
        "    disp_mc=random.sample(mc, 4)\n",
        "    print(\"Q:\",qtn)\n",
        "    i=1\n",
        "    for choice in disp_mc:\n",
        "        print(i,\".\",choice)\n",
        "        i=i+1\n",
        "    print(\"\\nAns:\",ans,\"\\n\")\n",
        "    questions.append(qtn)\n",
        "    answers.append(ans)\n",
        "    outF = open('questions.txt',\"a\")\n",
        "    outF.write(\"Q:\")\n",
        "    outF.write(qtn)\n",
        "    outF.write(\"\\n\")\n",
        "    outF.write(\"Options:\")\n",
        "    outF.write(str(disp_mc))\n",
        "    outF.write(\"\\nAns:\")\n",
        "    outF.write(ans)\n",
        "    outF.write(\"\\n\\n\")\n",
        "    outF.close()\n",
        "\n",
        "\n",
        "filename=sys.argv[1]\n",
        "with open(\"/content/input.txt\") as f:\n",
        "            text=f.read()\n",
        "f.close()\n",
        "collection=sent_tokenize(text)\n",
        "\n",
        "#find noun keywords from text\n",
        "r = Rake(min_length=1, max_length=1)\n",
        "r.extract_keywords_from_text(text)\n",
        "text_keys=r.get_ranked_phrases()\n",
        "text_keys_tagged=nltk.pos_tag(text_keys)\n",
        "for tag_key in text_keys_tagged:\n",
        "    if(tag_key[1]=='NNP'):\n",
        "        choices.append(tag_key[0])\n",
        "    if(tag_key[1]=='NNPS'):\n",
        "       choices.append(tag_key[0])\n",
        "    if(tag_key[1]=='NN'):\n",
        "        choices.append(tag_key[0])\n",
        "    if(tag_key[1]=='NNS'):\n",
        "        choices.append(tag_key[0])\n",
        "\n",
        "#find the relevant keywords from each sentence\n",
        "r = Rake(min_length=1, max_length=1)\n",
        "for collec in collection:\n",
        "    r.extract_keywords_from_text(collec)\n",
        "    if(r.get_ranked_phrases()):\n",
        "        phrase_list=r.get_ranked_phrases()\n",
        "        tagged=nltk.pos_tag(phrase_list)\n",
        "        #print(collec,\"\\t\",tagged,\"\\n\")\n",
        "        find_key(collec,tagged)"
      ],
      "metadata": {
        "id": "gCNIv_is4OyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b52f31-43c6-420b-8b58-fb5f610b24fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Harry Potter is a ________ of seven fantasy novels written by British author J. K. Rowling.\n",
            "1 . series\n",
            "2 . expand\n",
            "3 . drama\n",
            "4 . history\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Q: The novels chronicle the lives of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and ________.\n",
            "1 . find\n",
            "2 . wizardry\n",
            "3 . overthrow\n",
            "4 . thriller\n",
            "\n",
            "Ans: wizardry \n",
            "\n",
            "Q: The main story arc concerns Harry's conflict with Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic, and subjugate all wizards and Muggles (________-magical people).\n",
            "1 . non\n",
            "2 . spin\n",
            "3 . series\n",
            "4 . conflict\n",
            "\n",
            "Ans: non \n",
            "\n",
            "Q: The ________ was originally published in English by Bloomsbury in the United Kingdom and Scholastic Press in the United States.\n",
            "1 . series\n",
            "2 . time\n",
            "3 . adventure\n",
            "4 . history\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Q: A series of many genres, including fantasy, drama, coming-of-age fiction, and the British school story (which includes elements of mystery, thriller, adventure, horror, and romance), the ________ of Harry Potter explores numerous themes and includes many cultural meanings and references.\n",
            "1 . series\n",
            "2 . find\n",
            "3 . world\n",
            "4 . conflict\n",
            "\n",
            "Ans: world \n",
            "\n",
            "Q: [1] Major themes in the series include prejudice, corruption, ________, and death.\n",
            "1 . corruption\n",
            "2 . j\n",
            "3 . series\n",
            "4 . madness\n",
            "\n",
            "Ans: madness \n",
            "\n",
            "Q: [2][3]\n",
            "\n",
            "Since the release of the first novel, Harry Potter and the Philosopher's ________, on 26 June 1997, the books have found immense popularity, positive reviews, and commercial success worldwide.\n",
            "1 . time\n",
            "2 . expand\n",
            "3 . j\n",
            "4 . stone\n",
            "\n",
            "Ans: stone \n",
            "\n",
            "Q: [4][5] As of February 2023, the books have sold more than 600 million copies worldwide, making them the best-selling book series in ________, and have been available in 85 languages.\n",
            "1 . release\n",
            "2 . conflict\n",
            "3 . history\n",
            "4 . thriller\n",
            "\n",
            "Ans: history \n",
            "\n",
            "Q: [6] The last four books consecutively set records as the fastest-selling books in history, with the final instalment selling roughly 2.7 million copies in the United Kingdom and 8.3 million copies in the United States within twenty-four hours of its ________.\n",
            "1 . world\n",
            "2 . corruption\n",
            "3 . bloomsbury\n",
            "4 . release\n",
            "\n",
            "Ans: release \n",
            "\n",
            "Q: The original seven books were adapted into an eight-part namesake film series by Warner Bros. ________.\n",
            "1 . thriller\n",
            "2 . success\n",
            "3 . release\n",
            "4 . pictures\n",
            "\n",
            "Ans: pictures \n",
            "\n",
            "Q: In 2016, the total value of the Harry Potter franchise was estimated at $25 billion,[7] making Harry Potter one of the highest-grossing media franchises of all ________.\n",
            "1 . witchcraft\n",
            "2 . time\n",
            "3 . success\n",
            "4 . mystery\n",
            "\n",
            "Ans: time \n",
            "\n",
            "Q: The success of the books and films has allowed the Harry Potter franchise to expand with numerous derivative works, a travelling exhibition that premiered in Chicago in 2009, a studio tour in London that opened in 2012, a digital platform on which J. K. Rowling updates the series with new information and insight, and a ________ of spin-off films premiering in November 2016 with Fantastic Beasts and Where to Find Them, among many other developments.\n",
            "1 . mystery\n",
            "2 . release\n",
            "3 . history\n",
            "4 . trilogy\n",
            "\n",
            "Ans: trilogy \n",
            "\n",
            "Q: Themed attractions, collectively known as The Wizarding ________ of Harry Potter, have been built at several Universal Destinations & Experiences amusement parks around the world.\n",
            "1 . release\n",
            "2 . k\n",
            "3 . world\n",
            "4 . conflict\n",
            "\n",
            "Ans: world \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "# statistical analysis before cleaning the data\n",
        "# Read content from the text file\n",
        "file_path = \"/content/input.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Tokenize the text into words (assuming whitespace separation)\n",
        "words = content.split()\n",
        "\n",
        "# Calculate word frequency using Counter\n",
        "word_frequency = Counter(words)\n",
        "\n",
        "# Basic statistics\n",
        "total_words = len(words)\n",
        "unique_words = len(word_frequency)\n",
        "most_common_words = word_frequency.most_common(10)\n",
        "\n",
        "# Plot a bar chart of the most common words\n",
        "plt.bar(*zip(*most_common_words))\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Most Common Words')\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Total words: {total_words}\")\n",
        "print(f\"Unique words: {unique_words}\")\n",
        "print(\"Top 10 most common words:\")\n",
        "for word, frequency in most_common_words:\n",
        "    print(f\"{word}: {frequency}\")\n"
      ],
      "metadata": {
        "id": "hletI1IfRRDb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "cf9be6ad-7dcc-460a-b69e-b9b7f11c25ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 432\n",
            "Unique words: 260\n",
            "Top 10 most common words:\n",
            "the: 26\n",
            "and: 21\n",
            "of: 18\n",
            "in: 14\n",
            "a: 10\n",
            "Harry: 9\n",
            "Potter: 7\n",
            "series: 7\n",
            "The: 7\n",
            "books: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "id": "IGqFcMwYoSXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c672de-0742-419d-bc9b-a707c678d970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keybert\n",
            "  Downloading keybert-0.8.3.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.23.5)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.16.0+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=0.3.8->keybert)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (23.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.7)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Building wheels for collected packages: keybert, sentence-transformers\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.8.3-py3-none-any.whl size=39124 sha256=bff5823605626e1fd58371a9c5dd0a069e2709e9f44d68d4521a87456a7d97f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/88/07/1a3bc11fd1dd5f89924a02dcbca89a3015e25e8faa31f904dc\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=8ee8b1de721262d8493d4f911aeeaba95e70d903d076b2dc6dd78207c9329457\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built keybert sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers, keybert\n",
            "Successfully installed keybert-0.8.3 sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import re\n",
        "import string, sys, os\n",
        "from rake_nltk import Rake\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import io\n",
        "from io import StringIO\n",
        "import sys\n",
        "import random\n",
        "from transformers import pipeline\n",
        "from keybert import KeyBERT\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "choices = []\n",
        "\n",
        "def find_key(sent, tagged_list):\n",
        "    flag = 0\n",
        "    for tag in tagged_list:\n",
        "        if(tag[1] == 'NNP'):\n",
        "            key_word = tag[0]\n",
        "            flag = 1\n",
        "            break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NNPS'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NN'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "    if(flag == 0):\n",
        "        for tag in tagged_list:\n",
        "            if(tag[1] == 'NNS'):\n",
        "                key_word = tag[0]\n",
        "                flag = 1\n",
        "                break\n",
        "\n",
        "    if(flag == 1):\n",
        "        display(sent, key_word)\n",
        "\n",
        "def display(qtn, ans):\n",
        "    blank = '________'\n",
        "    qtn = re.sub(ans, blank, qtn, 1, flags=re.IGNORECASE)\n",
        "    mc = []\n",
        "    disp_mc = []\n",
        "    mc = random.sample(choices, 3)\n",
        "    mc.append(ans)\n",
        "    disp_mc = random.sample(mc, 4)\n",
        "\n",
        "    print(\"Q:\", qtn)\n",
        "    i = 1\n",
        "    for choice in disp_mc:\n",
        "        print(i, \".\", choice)\n",
        "        i = i + 1\n",
        "    print(\"\\nAns:\", ans, \"\\n\")\n",
        "\n",
        "    questions.append(qtn)\n",
        "    answers.append(ans)\n",
        "    outF = open('questions.txt', \"a\")\n",
        "    outF.write(\"Q:\")\n",
        "    outF.write(qtn)\n",
        "    outF.write(\"\\n\")\n",
        "    outF.write(\"Options:\")\n",
        "    outF.write(str(disp_mc))\n",
        "    outF.write(\"\\nAns:\")\n",
        "    outF.write(ans)\n",
        "    outF.write(\"\\n\\n\")\n",
        "    outF.close()\n",
        "\n",
        "# Read summary into text and tokenize text into sentences in collection\n",
        "filename = sys.argv[1]\n",
        "with open(\"/content/input.txt\") as f:\n",
        "    text = f.read()\n",
        "f.close()\n",
        "collection = sent_tokenize(text)\n",
        "\n",
        "# Find noun keywords from text using KeyBERT\n",
        "model = KeyBERT()\n",
        "keywords = model.extract_keywords(text)\n",
        "\n",
        "for keyword in keywords:\n",
        "    choices.append(keyword[0])\n",
        "\n",
        "# Create a T5 question answering pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"t5-base\", tokenizer=\"t5-base\")\n",
        "\n",
        "# Find the relevant keywords from each sentence\n",
        "r = Rake(min_length=1, max_length=1)\n",
        "for collec in collection:\n",
        "    r.extract_keywords_from_text(collec)\n",
        "    if(r.get_ranked_phrases()):\n",
        "        phrase_list = r.get_ranked_phrases()\n",
        "        tagged = nltk.pos_tag(phrase_list)\n",
        "        find_key(collec, tagged)\n",
        "        # Use T5 to answer a question about the sentence\n",
        "        result = qa_pipeline({\n",
        "            \"context\": collec,\n",
        "            \"question\": \"What is the main idea of this sentence?\"\n",
        "        })\n",
        "        main_idea = result[\"answer\"]\n",
        "        print(\"Main Idea:\", main_idea)"
      ],
      "metadata": {
        "id": "i-DsFq9N_kZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1dba0c-4e92-415a-dd97-0224f7558927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Harry Potter is a ________ of seven fantasy novels written by British author J. K. Rowling.\n",
            "1 . hogwarts\n",
            "2 . wizards\n",
            "3 . harry\n",
            "4 . series\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Main Idea: a series of seven fantasy novels\n",
            "Q: The novels chronicle the lives of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and ________.\n",
            "1 . wizardry\n",
            "2 . hogwarts\n",
            "3 . wizardry\n",
            "4 . wizards\n",
            "\n",
            "Ans: wizardry \n",
            "\n",
            "Main Idea: wizard, Harry Potter, and his friends\n",
            "Q: The main story arc concerns Harry's conflict with Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic, and subjugate all wizards and Muggles (________-magical people).\n",
            "1 . harry\n",
            "2 . wizards\n",
            "3 . potter\n",
            "4 . non\n",
            "\n",
            "Ans: non \n",
            "\n",
            "Main Idea: who intends to become immortal, overthrow\n",
            "Q: The ________ was originally published in English by Bloomsbury in the United Kingdom and Scholastic Press in the United States.\n",
            "1 . wizards\n",
            "2 . potter\n",
            "3 . wizardry\n",
            "4 . series\n",
            "\n",
            "Ans: series \n",
            "\n",
            "Main Idea: published in English by Bloomsbury in the United Kingdom and Scholastic\n",
            "Q: A series of many genres, including fantasy, drama, coming-of-age fiction, and the British school story (which includes elements of mystery, thriller, adventure, horror, and romance), the ________ of Harry Potter explores numerous themes and includes many cultural meanings and references.\n",
            "1 . world\n",
            "2 . wizards\n",
            "3 . hogwarts\n",
            "4 . harry\n",
            "\n",
            "Ans: world \n",
            "\n",
            "Main Idea: mystery, thriller, adventure, horror, and romance),\n",
            "Q: [1] Major themes in the series include prejudice, corruption, ________, and death.\n",
            "1 . potter\n",
            "2 . madness\n",
            "3 . wizards\n",
            "4 . hogwarts\n",
            "\n",
            "Ans: madness \n",
            "\n",
            "Main Idea: in the series include prejudice, corruption, madness,\n",
            "Q: [2][3]\n",
            "\n",
            "Since the release of the first novel, Harry Potter and the Philosopher's ________, on 26 June 1997, the books have found immense popularity, positive reviews, and commercial success worldwide.\n",
            "1 . hogwarts\n",
            "2 . stone\n",
            "3 . wizardry\n",
            "4 . wizards\n",
            "\n",
            "Ans: stone \n",
            "\n",
            "Main Idea: found immense popularity, positive reviews,\n",
            "Main Idea: of modern literature.\n",
            "Q: [4][5] As of February 2023, the books have sold more than 600 million copies worldwide, making them the best-selling book series in ________, and have been available in 85 languages.\n",
            "1 . wizardry\n",
            "2 . hogwarts\n",
            "3 . history\n",
            "4 . harry\n",
            "\n",
            "Ans: history \n",
            "\n",
            "Main Idea: in history, and have been available in 85 languages.\n",
            "Q: [6] The last four books consecutively set records as the fastest-selling books in history, with the final instalment selling roughly 2.7 million copies in the United Kingdom and 8.3 million copies in the United States within twenty-four hours of its ________.\n",
            "1 . release\n",
            "2 . wizardry\n",
            "3 . potter\n",
            "4 . harry\n",
            "\n",
            "Ans: release \n",
            "\n",
            "Main Idea: history, with the final instalment selling roughly 2.7 million copies\n",
            "Q: The original seven books were adapted into an eight-part namesake film series by Warner Bros. ________.\n",
            "1 . wizards\n",
            "2 . pictures\n",
            "3 . harry\n",
            "4 . hogwarts\n",
            "\n",
            "Ans: pictures \n",
            "\n",
            "Main Idea: by Warner Bros.\n",
            "Q: In 2016, the total value of the Harry Potter franchise was estimated at $25 billion,[7] making Harry Potter one of the highest-grossing media franchises of all ________.\n",
            "1 . wizardry\n",
            "2 . potter\n",
            "3 . time\n",
            "4 . hogwarts\n",
            "\n",
            "Ans: time \n",
            "\n",
            "Main Idea: value of the Harry Potter franchise was estimated at $25 billion,[7]\n",
            "Main Idea: and the Cursed Child is a play based on a\n",
            "Q: The success of the books and films has allowed the Harry Potter franchise to expand with numerous derivative works, a travelling exhibition that premiered in Chicago in 2009, a studio tour in London that opened in 2012, a digital platform on which J. K. Rowling updates the series with new information and insight, and a ________ of spin-off films premiering in November 2016 with Fantastic Beasts and Where to Find Them, among many other developments.\n",
            "1 . trilogy\n",
            "2 . wizardry\n",
            "3 . hogwarts\n",
            "4 . wizards\n",
            "\n",
            "Ans: trilogy \n",
            "\n",
            "Main Idea: insight, and a trilogy of spin-off films\n",
            "Q: Themed attractions, collectively known as The Wizarding ________ of Harry Potter, have been built at several Universal Destinations & Experiences amusement parks around the world.\n",
            "1 . wizards\n",
            "2 . world\n",
            "3 . harry\n",
            "4 . wizardry\n",
            "\n",
            "Ans: world \n",
            "\n",
            "Main Idea: built at several Universal Destinations & Experiences amusement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "id": "QIO6bKzmI8Xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7b92c3-87b8-4ae0-9230-e448cd80f5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "RVFvRBwbIpgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befb8b01-e5fc-4cde-ce99-a9d056753a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(questions, answers):\n",
        "    correct = 0\n",
        "    total = len(questions)\n",
        "\n",
        "    for i in range(total):\n",
        "        user_input = input(\"Q: \" + questions[i] + \"\\nYour answer: \")\n",
        "        if user_input.lower() == answers[i].lower():\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(\"Accuracy: \", accuracy, \"%\")\n",
        "\n",
        "# Rest of your code...\n",
        "\n",
        "# After generating the questions and answers\n",
        "evaluate(questions, answers)"
      ],
      "metadata": {
        "id": "WuUvju5yBeBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "abb43e0b-bee3-4dbb-c80f-710d011018b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: Harry Potter is a ________ of seven fantasy novels written by British author J. K. Rowling.\n",
            "Your answer: book\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c0029ab20f83>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# After generating the questions and answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-c0029ab20f83>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(questions, answers)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nYour answer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the library to evaluate the model\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "249rL3HOMq9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc32dc3-a780-49d3-ce69-5eb95449dc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=7a7a831088b4f7a97216cbab831b7227040d6335ecb49e73f0ec4a9ba485168d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert txt file to string\n",
        "file_path = \"/content/input.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    file_content = file.read()"
      ],
      "metadata": {
        "id": "zp477TtnM8jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert questions list into string\n",
        "string_questions = ''.join(questions)"
      ],
      "metadata": {
        "id": "2DLqCdclNKhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to save the questions without underscore\n",
        "text_with_underscores = string_questions\n",
        "\n",
        "# Remove underscores using replace\n",
        "text_without_underscores = text_with_underscores.replace(\"_\", \"\")"
      ],
      "metadata": {
        "id": "CE3hNEBCNZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to save the questions without periods\n",
        "text_with_period = text_without_underscores\n",
        "\n",
        "# Remove period using replace\n",
        "text_without_period = text_with_period.replace(\".\", \" \")"
      ],
      "metadata": {
        "id": "anGeGf0zN8lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# variable to save file content\n",
        "text = file_content\n",
        "\n",
        "# Convert everything to lowercase.\n",
        "text = text.lower()\n",
        "\n",
        "# Define a regular expression pattern to match non-alphanumeric characters\n",
        "NON_ALPHANUM_RE = re.compile(r'[^a-zA-Z0-9]')\n",
        "\n",
        "# Replace any non-alpha-numeric characters with spaces.\n",
        "text = NON_ALPHANUM_RE.sub(\" \", text)\n"
      ],
      "metadata": {
        "id": "M4DJxMyOOmm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# variable to save cleaned questions\n",
        "textQ = text_without_period\n",
        "\n",
        "# Convert everything to lowercase.\n",
        "textQ = text.lower()\n",
        "\n",
        "# Define a regular expression pattern to match non-alphanumeric characters\n",
        "NON_ALPHANUM_RE = re.compile(r'[^a-zA-Z0-9]')\n",
        "\n",
        "# Replace any non-alpha-numeric characters with spaces.\n",
        "textQ = NON_ALPHANUM_RE.sub(\" \", textQ)\n",
        "\n",
        "# Now, 'text' contains the modified string with lowercase and non-alphanumeric characters replaced by spaces.\n",
        "print(textQ)"
      ],
      "metadata": {
        "id": "gaQtXkL3OxdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662ab0d0-9a75-490e-d2d5-26e9fc6b8f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harry potter is a series of seven fantasy novels written by british author j  k  rowling  the novels chronicle the lives of a young wizard  harry potter  and his friends hermione granger and ron weasley  all of whom are students at hogwarts school of witchcraft and wizardry  the main story arc concerns harry s conflict with lord voldemort  a dark wizard who intends to become immortal  overthrow the wizard governing body known as the ministry of magic  and subjugate all wizards and muggles  non magical people    the series was originally published in english by bloomsbury in the united kingdom and scholastic press in the united states  a series of many genres  including fantasy  drama  coming of age fiction  and the british school story  which includes elements of mystery  thriller  adventure  horror  and romance   the world of harry potter explores numerous themes and includes many cultural meanings and references  1  major themes in the series include prejudice  corruption  madness  and death  2  3   since the release of the first novel  harry potter and the philosopher s stone  on 26 june 1997  the books have found immense popularity  positive reviews  and commercial success worldwide  they have attracted a wide adult audience as well as younger readers  and are widely considered cornerstones of modern literature  4  5  as of february 2023  the books have sold more than 600 million copies worldwide  making them the best selling book series in history  and have been available in 85 languages  6  the last four books consecutively set records as the fastest selling books in history  with the final instalment selling roughly 2 7 million copies in the united kingdom and 8 3 million copies in the united states within twenty four hours of its release   the original seven books were adapted into an eight part namesake film series by warner bros  pictures  in 2016  the total value of the harry potter franchise was estimated at  25 billion  7  making harry potter one of the highest grossing media franchises of all time  harry potter and the cursed child is a play based on a story co written by rowling   the success of the books and films has allowed the harry potter franchise to expand with numerous derivative works  a travelling exhibition that premiered in chicago in 2009  a studio tour in london that opened in 2012  a digital platform on which j  k  rowling updates the series with new information and insight  and a trilogy of spin off films premiering in november 2016 with fantastic beasts and where to find them  among many other developments  themed attractions  collectively known as the wizarding world of harry potter  have been built at several universal destinations   experiences amusement parks around the world  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qffX3W8Naa8Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}